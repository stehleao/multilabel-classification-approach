{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Mining non-functional requirements </center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run imports.ipynb\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('bases/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text'] = data['content_review'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_review</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "      <th>domain_name</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label_dep</th>\n",
       "      <th>label_per</th>\n",
       "      <th>label_sup</th>\n",
       "      <th>label_usa</th>\n",
       "      <th>label_mis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love the app, I have used it for years The o...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>PhotosVideos</td>\n",
       "      <td>Usa</td>\n",
       "      <td>[love, app, use, year, problem, new, update, w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It would be better if they actually released t...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>PhotosVideos</td>\n",
       "      <td>Mis</td>\n",
       "      <td>[good, actually, release, message, instead, ju...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Needs to be an option to pay monthly, or to op...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>PhotosVideos</td>\n",
       "      <td>Mis</td>\n",
       "      <td>[need, option, pay, monthly, open, deleted, pi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Please let there be a one week free trial I wo...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>PhotosVideos</td>\n",
       "      <td>Mis</td>\n",
       "      <td>[let, week, free, trial, premium, like, try]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can\\'t connect to server. Failed big time. Ple...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>PhotosVideos</td>\n",
       "      <td>Sup</td>\n",
       "      <td>[t, connect, server, fail, big, time, fix, pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>I followed all the instructions airplane mode,...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>Mis</td>\n",
       "      <td>[follow, instruction, airplane, mode, listen, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>What a disappointment for 4.99 Ugh</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>Mis</td>\n",
       "      <td>[disappointment, ugh]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>I hate it ... this app does not work.</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>Usa</td>\n",
       "      <td>[hate, app, work]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>Im at 28 weeks, and I was able to listen to my...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>Mis</td>\n",
       "      <td>[im, week, able, listen, babys, heart, beat, j...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>I have had this app downloaded since I was may...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>Mis</td>\n",
       "      <td>[app, download, maybe, week, pregnant, placent...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         content_review sentiment_analysis  \\\n",
       "0     I love the app, I have used it for years The o...           Positive   \n",
       "1     It would be better if they actually released t...           Positive   \n",
       "2     Needs to be an option to pay monthly, or to op...           Negative   \n",
       "3     Please let there be a one week free trial I wo...           Positive   \n",
       "4     Can\\'t connect to server. Failed big time. Ple...           Negative   \n",
       "...                                                 ...                ...   \n",
       "5995  I followed all the instructions airplane mode,...            Neutral   \n",
       "5996                What a disappointment for 4.99 Ugh            Negative   \n",
       "5997              I hate it ... this app does not work.           Negative   \n",
       "5998  Im at 28 weeks, and I was able to listen to my...           Positive   \n",
       "5999  I have had this app downloaded since I was may...           Positive   \n",
       "\n",
       "       domain_name label                                         clean_text  \\\n",
       "0     PhotosVideos   Usa  [love, app, use, year, problem, new, update, w...   \n",
       "1     PhotosVideos   Mis  [good, actually, release, message, instead, ju...   \n",
       "2     PhotosVideos   Mis  [need, option, pay, monthly, open, deleted, pi...   \n",
       "3     PhotosVideos   Mis       [let, week, free, trial, premium, like, try]   \n",
       "4     PhotosVideos   Sup  [t, connect, server, fail, big, time, fix, pro...   \n",
       "...            ...   ...                                                ...   \n",
       "5995     Lifestyle   Mis  [follow, instruction, airplane, mode, listen, ...   \n",
       "5996     Lifestyle   Mis                              [disappointment, ugh]   \n",
       "5997     Lifestyle   Usa                                  [hate, app, work]   \n",
       "5998     Lifestyle   Mis  [im, week, able, listen, babys, heart, beat, j...   \n",
       "5999     Lifestyle   Mis  [app, download, maybe, week, pregnant, placent...   \n",
       "\n",
       "      label_dep  label_per  label_sup  label_usa  label_mis  \n",
       "0             0          0          0          1          0  \n",
       "1             0          0          0          0          1  \n",
       "2             0          0          0          0          1  \n",
       "3             0          0          0          0          1  \n",
       "4             0          0          1          0          0  \n",
       "...         ...        ...        ...        ...        ...  \n",
       "5995          0          0          0          0          1  \n",
       "5996          0          0          0          0          1  \n",
       "5997          0          0          0          1          0  \n",
       "5998          0          0          0          0          1  \n",
       "5999          0          0          0          0          1  \n",
       "\n",
       "[6000 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels  = []\n",
    "\n",
    "for i in data['label']:\n",
    "    a = i.split(',')\n",
    "    labels.append(a)\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=(\"Dep\", \"Per\", \"Sup\", \"Usa\", \"Mis\"))\n",
    "labelsdf = pd.DataFrame(mlb.fit_transform(labels), columns=['Dep', 'Per', 'Sup', 'Usa', 'Mis']) \n",
    "data = data.assign(label_dep=labelsdf['Dep'].values, label_per=labelsdf['Per'].values, label_sup=labelsdf['Sup'].values, label_usa=labelsdf['Usa'].values, label_mis=labelsdf['Mis'].values)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dep = data.loc[data['label_dep'] == True] \n",
    "data_dep = data_dep.drop(columns=['label_per', 'label_sup', 'label_usa', 'label_mis'])\n",
    "text_dep = data_dep['clean_text'].tolist()\n",
    "\n",
    "data_per = data.loc[data['label_per'] == True]\n",
    "data_per = data_per.drop(columns=['label_dep', 'label_sup', 'label_usa', 'label_mis'])\n",
    "text_per = data_per['clean_text'].tolist()\n",
    "\n",
    "data_sup = data.loc[data['label_sup'] == True] \n",
    "data_sup = data_sup.drop(columns=['label_dep', 'label_per', 'label_usa', 'label_mis'])\n",
    "text_sup = data_sup['clean_text'].tolist()\n",
    "\n",
    "data_usa = data.loc[data['label_usa'] == True] \n",
    "data_usa = data_usa.drop(columns=['label_dep', 'label_per', 'label_sup', 'label_mis'])\n",
    "text_usa = data_usa['clean_text'].tolist()\n",
    "\n",
    "data_mis = data.loc[data['label_mis'] == True] \n",
    "data_mis = data_mis.drop(columns=['label_dep', 'label_per', 'label_sup', 'label_usa'])\n",
    "text_mis = data_mis['clean_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 10628)\n",
      "(6000, 4)\n"
     ]
    }
   ],
   "source": [
    "texts = data['clean_text'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df = 2, max_df = .95)\n",
    "\n",
    "bow_vectorizer = CountVectorizer(ngram_range=(1, 2), min_df = 2, max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "# X = bow_vectorizer.fit_transform(texts)\n",
    "y = data.iloc[:, 5:9]. values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa = TruncatedSVD(n_components=100, n_iter=10, random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((4800, 100), (4800, 4)), ((1200, 100), (1200, 4)))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X, y, test_size=0.2)\n",
    "((X_train.shape, y_train.shape), (X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-multilearn classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. BRkNN classifiers train a k Nearest Neighbor per label and use infer label assignment in one of the two variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.6008333333333333\n",
      "Precision =  0.4267253136933988\n",
      "Recall =  0.16063929277244496\n",
      "F1 Score =  0.22678716034510224\n",
      "Hamming loss =  0.12083333333333333\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import BRkNNaClassifier\n",
    "\n",
    "classifierBRkNNa = BRkNNaClassifier(k=3)\n",
    "classifierBRkNNa.fit(X_train, y_train)\n",
    "predictionBRkNNa = classifierBRkNNa.predict(X_test)\n",
    "\n",
    "print(\"Accuracy = \", accuracy_score(y_test, predictionBRkNNa))\n",
    "print(\"Precision = \", precision_score(y_test, predictionBRkNNa, average = 'macro'))\n",
    "print(\"Recall = \", recall_score(y_test, predictionBRkNNa, average = 'macro'))\n",
    "print(\"F1 Score = \", f1_score(y_test, predictionBRkNNa, average = 'macro'))\n",
    "#print(\"Hamming score = \", hamming_score(y_test, predictionBRkNNa))\n",
    "print(\"Hamming loss = \", hamming_loss(y_test, predictionBRkNNa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. MLkNN builds uses k-NearestNeighbors find nearest examples to a test class and uses Bayesian inference to select assigned labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.6008333333333333\n",
      "Precision =  0.4267253136933988\n",
      "Recall =  0.16063929277244496\n",
      "F1 Score =  0.22678716034510224\n",
      "Hamming loss =  0.12083333333333333\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "\n",
    "classifierMLkNN = MLkNN(k=3)\n",
    "classifierMLkNN.fit(X_train, y_train)\n",
    "predictionMLkNN = classifierMLkNN.predict(X_test)\n",
    "\n",
    "print(\"Accuracy = \", accuracy_score(y_test, predictionMLkNN))\n",
    "print(\"Precision = \", precision_score(y_test, predictionMLkNN, average = 'macro'))\n",
    "print(\"Recall = \", recall_score(y_test, predictionMLkNN, average = 'macro'))\n",
    "print(\"F1 Score = \", f1_score(y_test, predictionBRkNNa, average = 'macro'))\n",
    "# print(\"Hamming score = \", hamming_score(y_test, predictionMLkNN))\n",
    "print(\"Hamming loss = \", hamming_loss(y_test, predictionMLkNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. An ART classifier which uses clustering of learned prototypes into large clusters improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.15583333333333332\n",
      "Precision =  0.23322606065113316\n",
      "Recall =  0.4975972849614154\n",
      "F1 Score =  0.3002349220159949\n",
      "Hamming score =  0.21340277777777777\n",
      "Hamming loss =  0.2816666666666667\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLARAM\n",
    "\n",
    "classifierMLARAM = MLARAM(threshold=0.05, vigilance=0.95)\n",
    "classifierMLARAM.fit(X_train, y_train)\n",
    "predictionMLARAM = classifierMLARAM.predict(X_test)\n",
    "\n",
    "print(\"Accuracy = \", accuracy_score(y_test, predictionMLARAM))\n",
    "print(\"Precision = \", precision_score(y_test, predictionMLARAM, average = 'macro'))\n",
    "print(\"Recall = \", recall_score(y_test, predictionMLARAM, average = 'macro'))\n",
    "print(\"F1 Score = \", f1_score(y_test, predictionMLARAM, average = 'macro'))\n",
    "print(\"Hamming score = \", hamming_score(y_test, predictionMLARAM))\n",
    "print(\"Hamming loss = \", hamming_loss(y_test, predictionMLARAM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Transforms a multi-label classification problem with L labels into L single-label separate binary classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-a01e86874aaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclassifierBRSVC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBinaryRelevance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mclassifierBRSVC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mpredictionBRSVC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifierBRSVC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\skmultilearn\\problem_transform\\br.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_subset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my_subset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my_subset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[0my_subset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_subset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             classifier.fit(self._ensure_input_format(\n\u001b[0m\u001b[0;32m    162\u001b[0m                 X), self._ensure_output_format(y_subset))\n\u001b[0;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifiers_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_counters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_effective_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m         \u001b[1;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m         \u001b[0mcheck_non_negative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MultinomialNB (input X)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mX_min\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifierBRSVC = BinaryRelevance(classifier = MultinomialNB())\n",
    "classifierBRSVC.fit(X_train, y_train)\n",
    "predictionBRSVC = classifierBRSVC.predict(X_test)\n",
    "\n",
    "print(\"Accuracy = \", accuracy_score(y_test, predictionBRSVC))\n",
    "print(\"Precision = \", precision_score(y_test, predictionBRSVC, average = 'macro'))\n",
    "print(\"Recall = \", recall_score(y_test, predictionBRSVC, average = 'macro'))\n",
    "print(\"F1 Score = \", f1_score(y_test, predictionBRSVC, average = 'macro'))\n",
    "print(\"Hamming score = \", hamming_score(y_test, predictionBRSVC))\n",
    "print(\"Hamming loss = \", hamming_loss(y_test, predictionBRSVC))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
