{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Mining non-functional requirements </center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run imports.ipynb\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('bases/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text'] = data['content_review'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_review</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "      <th>domain_name</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label_dep</th>\n",
       "      <th>label_per</th>\n",
       "      <th>label_sup</th>\n",
       "      <th>label_usa</th>\n",
       "      <th>label_mis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love the app, I have used it for years The o...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>PhotosVideos</td>\n",
       "      <td>Usa</td>\n",
       "      <td>[love, app, use, year, problem, new, update, w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It would be better if they actually released t...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>PhotosVideos</td>\n",
       "      <td>Mis</td>\n",
       "      <td>[good, actually, release, message, instead, ju...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Needs to be an option to pay monthly, or to op...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>PhotosVideos</td>\n",
       "      <td>Mis</td>\n",
       "      <td>[need, option, pay, monthly, open, deleted, pi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Please let there be a one week free trial I wo...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>PhotosVideos</td>\n",
       "      <td>Mis</td>\n",
       "      <td>[let, week, free, trial, premium, like, try]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can\\'t connect to server. Failed big time. Ple...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>PhotosVideos</td>\n",
       "      <td>Sup</td>\n",
       "      <td>[t, connect, server, fail, big, time, fix, pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>I followed all the instructions airplane mode,...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>Mis</td>\n",
       "      <td>[follow, instruction, airplane, mode, listen, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>What a disappointment for 4.99 Ugh</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>Mis</td>\n",
       "      <td>[disappointment, ugh]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>I hate it ... this app does not work.</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>Usa</td>\n",
       "      <td>[hate, app, work]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>Im at 28 weeks, and I was able to listen to my...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>Mis</td>\n",
       "      <td>[im, week, able, listen, babys, heart, beat, j...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>I have had this app downloaded since I was may...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>Mis</td>\n",
       "      <td>[app, download, maybe, week, pregnant, placent...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         content_review sentiment_analysis  \\\n",
       "0     I love the app, I have used it for years The o...           Positive   \n",
       "1     It would be better if they actually released t...           Positive   \n",
       "2     Needs to be an option to pay monthly, or to op...           Negative   \n",
       "3     Please let there be a one week free trial I wo...           Positive   \n",
       "4     Can\\'t connect to server. Failed big time. Ple...           Negative   \n",
       "...                                                 ...                ...   \n",
       "5995  I followed all the instructions airplane mode,...            Neutral   \n",
       "5996                What a disappointment for 4.99 Ugh            Negative   \n",
       "5997              I hate it ... this app does not work.           Negative   \n",
       "5998  Im at 28 weeks, and I was able to listen to my...           Positive   \n",
       "5999  I have had this app downloaded since I was may...           Positive   \n",
       "\n",
       "       domain_name label                                         clean_text  \\\n",
       "0     PhotosVideos   Usa  [love, app, use, year, problem, new, update, w...   \n",
       "1     PhotosVideos   Mis  [good, actually, release, message, instead, ju...   \n",
       "2     PhotosVideos   Mis  [need, option, pay, monthly, open, deleted, pi...   \n",
       "3     PhotosVideos   Mis       [let, week, free, trial, premium, like, try]   \n",
       "4     PhotosVideos   Sup  [t, connect, server, fail, big, time, fix, pro...   \n",
       "...            ...   ...                                                ...   \n",
       "5995     Lifestyle   Mis  [follow, instruction, airplane, mode, listen, ...   \n",
       "5996     Lifestyle   Mis                              [disappointment, ugh]   \n",
       "5997     Lifestyle   Usa                                  [hate, app, work]   \n",
       "5998     Lifestyle   Mis  [im, week, able, listen, babys, heart, beat, j...   \n",
       "5999     Lifestyle   Mis  [app, download, maybe, week, pregnant, placent...   \n",
       "\n",
       "      label_dep  label_per  label_sup  label_usa  label_mis  \n",
       "0             0          0          0          1          0  \n",
       "1             0          0          0          0          1  \n",
       "2             0          0          0          0          1  \n",
       "3             0          0          0          0          1  \n",
       "4             0          0          1          0          0  \n",
       "...         ...        ...        ...        ...        ...  \n",
       "5995          0          0          0          0          1  \n",
       "5996          0          0          0          0          1  \n",
       "5997          0          0          0          1          0  \n",
       "5998          0          0          0          0          1  \n",
       "5999          0          0          0          0          1  \n",
       "\n",
       "[6000 rows x 10 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels  = []\n",
    "\n",
    "for i in data['label']:\n",
    "    a = i.split(',')\n",
    "    labels.append(a)\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=(\"Dep\", \"Per\", \"Sup\", \"Usa\", \"Mis\"))\n",
    "labelsdf = pd.DataFrame(mlb.fit_transform(labels), columns=['Dep', 'Per', 'Sup', 'Usa', 'Mis']) \n",
    "data = data.assign(label_dep=labelsdf['Dep'].values, label_per=labelsdf['Per'].values, label_sup=labelsdf['Sup'].values, label_usa=labelsdf['Usa'].values, label_mis=labelsdf['Mis'].values)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dep = data.loc[data['label_dep'] == True] \n",
    "data_dep = data_dep.drop(columns=['label_per', 'label_sup', 'label_usa', 'label_mis'])\n",
    "text_dep = data_dep['clean_text'].tolist()\n",
    "\n",
    "data_per = data.loc[data['label_per'] == True]\n",
    "data_per = data_per.drop(columns=['label_dep', 'label_sup', 'label_usa', 'label_mis'])\n",
    "text_per = data_per['clean_text'].tolist()\n",
    "\n",
    "data_sup = data.loc[data['label_sup'] == True] \n",
    "data_sup = data_sup.drop(columns=['label_dep', 'label_per', 'label_usa', 'label_mis'])\n",
    "text_sup = data_sup['clean_text'].tolist()\n",
    "\n",
    "data_usa = data.loc[data['label_usa'] == True] \n",
    "data_usa = data_usa.drop(columns=['label_dep', 'label_per', 'label_sup', 'label_mis'])\n",
    "text_usa = data_usa['clean_text'].tolist()\n",
    "\n",
    "data_mis = data.loc[data['label_mis'] == True] \n",
    "data_mis = data_mis.drop(columns=['label_dep', 'label_per', 'label_sup', 'label_usa'])\n",
    "text_mis = data_mis['clean_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 10628)\n",
      "(6000, 5)\n"
     ]
    }
   ],
   "source": [
    "texts = data['clean_text'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), min_df = 2, max_df = .95)\n",
    "\n",
    "bow_vectorizer = CountVectorizer(ngram_range=(1, 2), min_df = 2, max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "# X = bow_vectorizer.fit_transform(texts)\n",
    "#y = data.iloc[:, 5:9].values\n",
    "y = data.iloc[:, 5:10].values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 100)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa = TruncatedSVD(n_components=100, n_iter=10, random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((4798, 100), (4798, 5)), ((1202, 100), (1202, 5)))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X, y, test_size=0.2)\n",
    "((X_train.shape, y_train.shape), (X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-multilearn classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. BRkNNaClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.5965058236272879\n",
      "Precision =  0.5663651155222909\n",
      "Recall =  0.3208320143843859\n",
      "F1 Score =  0.3668882407044985\n",
      "Hamming loss =  0.14675540765391015\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import BRkNNaClassifier\n",
    "\n",
    "classifierBRkNNa = BRkNNaClassifier(k=3)\n",
    "classifierBRkNNa.fit(X_train, y_train)\n",
    "predictionBRkNNa = classifierBRkNNa.predict(X_test)\n",
    "\n",
    "print(\"Accuracy = \", accuracy_score(y_test, predictionBRkNNa))\n",
    "print(\"Precision = \", precision_score(y_test, predictionBRkNNa, average = 'macro'))\n",
    "print(\"Recall = \", recall_score(y_test, predictionBRkNNa, average = 'macro'))\n",
    "print(\"F1 Score = \", f1_score(y_test, predictionBRkNNa, average = 'macro'))\n",
    "#print(\"Hamming score = \", hamming_score(y_test, predictionBRkNNa))\n",
    "print(\"Hamming loss = \", hamming_loss(y_test, predictionBRkNNa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. MLkNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.5965058236272879\n",
      "Precision =  0.5663651155222909\n",
      "Recall =  0.3208320143843859\n",
      "F1 Score =  0.3668882407044985\n",
      "Hamming loss =  0.14675540765391015\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "\n",
    "classifierMLkNN = MLkNN(k=3)\n",
    "classifierMLkNN.fit(X_train, y_train)\n",
    "predictionMLkNN = classifierMLkNN.predict(X_test)\n",
    "\n",
    "print(\"Accuracy = \", accuracy_score(y_test, predictionMLkNN))\n",
    "print(\"Precision = \", precision_score(y_test, predictionMLkNN, average = 'macro'))\n",
    "print(\"Recall = \", recall_score(y_test, predictionMLkNN, average = 'macro'))\n",
    "print(\"F1 Score = \", f1_score(y_test, predictionBRkNNa, average = 'macro'))\n",
    "# print(\"Hamming score = \", hamming_score(y_test, predictionMLkNN))\n",
    "print(\"Hamming loss = \", hamming_loss(y_test, predictionMLkNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. MLARAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.5840266222961731\n",
      "Precision =  0.4729822865306737\n",
      "Recall =  0.405906395975566\n",
      "F1 Score =  0.410052112404866\n",
      "Hamming score =  0.6485718247365502\n",
      "Hamming loss =  0.16356073211314476\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLARAM\n",
    "\n",
    "classifierMLARAM = MLARAM(threshold=0.05, vigilance=0.95)\n",
    "classifierMLARAM.fit(X_train, y_train)\n",
    "predictionMLARAM = classifierMLARAM.predict(X_test)\n",
    "\n",
    "print(\"Accuracy = \", accuracy_score(y_test, predictionMLARAM))\n",
    "print(\"Precision = \", precision_score(y_test, predictionMLARAM, average = 'macro'))\n",
    "print(\"Recall = \", recall_score(y_test, predictionMLARAM, average = 'macro'))\n",
    "print(\"F1 Score = \", f1_score(y_test, predictionMLARAM, average = 'macro'))\n",
    "print(\"Hamming score = \", hamming_score(y_test, predictionMLARAM))\n",
    "print(\"Hamming loss = \", hamming_loss(y_test, predictionMLARAM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. BinaryRelevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifierBRSVC = BinaryRelevance(classifier = SVC(), require_dense = [False, True])\n",
    "classifierBRSVC.fit(X_train, y_train)\n",
    "predictionBRSVC = classifierBRSVC.predict(X_test)\n",
    "\n",
    "#print(\"Accuracy = \", accuracy_score(y_test, predictionBRSVC))\n",
    "#print(\"Precision = \", precision_score(y_test, predictionBRSVC, average = 'macro'))\n",
    "#print(\"Recall = \", recall_score(y_test, predictionBRSVC, average = 'macro'))\n",
    "#print(\"F1 Score = \", f1_score(y_test, predictionBRSVC, average = 'macro'))\n",
    "#print(\"Hamming score = \", hamming_score(y_test, predictionBRSVC))\n",
    "#print(\"Hamming loss = \", hamming_loss(y_test, predictionBRSVC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. ClassifierChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifierCCSVC = ClassifierChain(classifier = SVC(), require_dense = [False, True])\n",
    "classifierCCSVC.fit(X_train, y_train)\n",
    "predictionCCSVC = classifierCCSVC.predict(X_test)\n",
    "\n",
    "\n",
    "#print(\"Accuracy = \", accuracy_score(y_test, predictionCCSVC))\n",
    "#print(\"Precision = \", precision_score(y_test, predictionCCSVC, average = 'macro'))\n",
    "#print(\"Recall = \", recall_score(y_test, predictionCCSVC, average = 'macro'))\n",
    "#print(\"F1 Score = \", f1_score(y_test, predictionCCSVC, average = 'macro'))\n",
    "#print(\"Hamming score = \", hamming_score(y_test, predictionCCSVC))\n",
    "#print(\"Hamming loss = \", hamming_loss(y_test, predictionCCSVC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. LabelPowerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifierCCRF = ClassifierChain(classifier = RandomForestClassifier(n_estimators=100), require_dense = [False, True])\n",
    "classifierCCRF.fit(X_train, y_train)\n",
    "predictionCCRF = classifierCCRF.predict(X_test)\n",
    "\n",
    "#print(\"Accuracy = \", accuracy_score(y_test, predictionCCRF))\n",
    "#print(\"Precision = \", precision_score(y_test, predictionCCRF, average = 'macro'))\n",
    "#print(\"Recall = \", recall_score(y_test, predictionCCRF, average = 'macro'))\n",
    "#print(\"F1 Score = \", f1_score(y_test, predictionCCRF, average = 'macro'))\n",
    "#print(\"Hamming score = \", hamming_score(y_test, predictionCCRF))\n",
    "#print(\"Hamming loss = \", hamming_loss(y_test, predictionCCRF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. RakelD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.5141430948419301\n",
      "Precision =  0.38962680370830627\n",
      "Recall =  0.45228345710065077\n",
      "F1 Score =  0.4056263916218086\n",
      "Hamming loss =  0.19600665557404326\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from skmultilearn.ensemble import RakelD\n",
    "\n",
    "classifierRD = RakelD(base_classifier=GaussianNB(), base_classifier_require_dense=[True, True], labelset_size=4)\n",
    "classifierRD.fit(X_train, y_train)\n",
    "predictionRD = classifierRD.predict(X_test)\n",
    "\n",
    "print(\"Accuracy = \", accuracy_score(y_test, predictionRD))\n",
    "print(\"Precision = \", precision_score(y_test, predictionRD, average = 'macro'))\n",
    "print(\"Recall = \", recall_score(y_test, predictionRD, average = 'macro'))\n",
    "print(\"F1 Score = \", f1_score(y_test, predictionRD, average = 'macro'))\n",
    "#print(\"Hamming score = \", hamming_score(y_test, predictionRD))\n",
    "print(\"Hamming loss = \", hamming_loss(y_test, predictionRD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. MajorityVotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.ensemble import MajorityVotingClassifier\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#classifierMV = MajorityVotingClassifier(classifier = ClassifierChain(classifier=GaussianNB()))\n",
    "#classifierMV.fit(X_train, y_train)\n",
    "#predictionsMV = classifierMV.predict(X_test)\n",
    "\n",
    "#print(\"Accuracy = \", accuracy_score(y_test, predictionsMV))\n",
    "#print(\"Precision = \", precision_score(y_test, predictionsMV, average = 'macro'))\n",
    "#print(\"Recall = \", recall_score(y_test, predictionsMV, average = 'macro'))\n",
    "#print(\"F1 Score = \", f1_score(y_test, predictionsMV, average = 'macro'))\n",
    "#print(\"Hamming score = \", hamming_score(y_test, predictionsMV))\n",
    "#print(\"Hamming loss = \", hamming_loss(y_test, predictionsMV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
