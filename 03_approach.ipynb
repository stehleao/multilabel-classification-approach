{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run imports.ipynb\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('bases/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_review</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "      <th>domain_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love the app, I have used it for years The o...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>PhotosVideos</td>\n",
       "      <td>Usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It would be better if they actually released t...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>PhotosVideos</td>\n",
       "      <td>Mis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Needs to be an option to pay monthly, or to op...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>PhotosVideos</td>\n",
       "      <td>Mis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Please let there be a one week free trial I wo...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>PhotosVideos</td>\n",
       "      <td>Mis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can\\'t connect to server. Failed big time. Ple...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>PhotosVideos</td>\n",
       "      <td>Sup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      content_review sentiment_analysis  \\\n",
       "0  I love the app, I have used it for years The o...           Positive   \n",
       "1  It would be better if they actually released t...           Positive   \n",
       "2  Needs to be an option to pay monthly, or to op...           Negative   \n",
       "3  Please let there be a one week free trial I wo...           Positive   \n",
       "4  Can\\'t connect to server. Failed big time. Ple...           Negative   \n",
       "\n",
       "    domain_name label  \n",
       "0  PhotosVideos   Usa  \n",
       "1  PhotosVideos   Mis  \n",
       "2  PhotosVideos   Mis  \n",
       "3  PhotosVideos   Mis  \n",
       "4  PhotosVideos   Sup  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "import gensim.parsing.preprocessing as gsp\n",
    "\n",
    "filters = [\n",
    "           gsp.strip_tags, \n",
    "           gsp.strip_punctuation,\n",
    "           gsp.strip_multiple_whitespaces,\n",
    "           gsp.strip_numeric,\n",
    "           gsp.remove_stopwords, \n",
    "           gsp.strip_short, \n",
    "           gsp.stem_text\n",
    "          ]\n",
    "\n",
    "def clean_text(s):\n",
    "    s = s.lower()\n",
    "    s = utils.to_unicode(s)\n",
    "    for f in filters:\n",
    "        s = f(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I love the app, I have used it for years The only problem is that with the new update, it won't allow me to add videos. Please fix it.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love app year problem new updat won allow add video fix'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(data.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = data[['content_review']]\n",
    "df_y = data[['label']]\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "y = []\n",
    "for index, row in df_y.iterrows():\n",
    "    y.append(set(row['label'].split(',')))\n",
    "    \n",
    "mlb = MultiLabelBinarizer()\n",
    "encoded_y = mlb.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn import utils as skl_utils\n",
    "from tqdm import tqdm\n",
    "\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "class Doc2VecTransformer(BaseEstimator):\n",
    "\n",
    "    def __init__(self, vector_size=100, learning_rate=0.02, epochs=20, field=None):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self._model = None\n",
    "        self.vector_size = vector_size\n",
    "        self.workers = multiprocessing.cpu_count() - 1\n",
    "        self.field = field\n",
    "\n",
    "    def fit(self, df_x, df_y=None):\n",
    "        tagged_x = [TaggedDocument(clean_text(row[str(self.field)]).split(), [index]) for index, row in df_x.iterrows()]\n",
    "        model = Doc2Vec(documents=tagged_x, vector_size=self.vector_size, workers=self.workers)\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            model.train(skl_utils.shuffle([x for x in tqdm(tagged_x)]), total_examples=len(tagged_x), epochs=1)\n",
    "            model.alpha -= self.learning_rate\n",
    "            model.min_alpha = model.alpha\n",
    "\n",
    "        self._model = model\n",
    "        return self\n",
    "\n",
    "    def transform(self, df_x):\n",
    "        return np.asmatrix(np.array([self._model.infer_vector(clean_text(row[str(self.field)]).split())\n",
    "                                     for index, row in df_x.iterrows()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(df_x, encoded_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "fu = FeatureUnion(transformer_list=[('title_doc2vec',Doc2VecTransformer(field='content_review'))])\n",
    "\n",
    "binary_rel_model = BinaryRelevance(RandomForestClassifier(n_jobs=-1))\n",
    "multi_label_rf_br_model = Pipeline(steps=[\n",
    "                           ('feature_union', fu),\n",
    "                           ('binary_relevance', binary_rel_model)\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "def hamming_loss(multi_label_model_pipeline,train_x, train_y, test_x, test_y):\n",
    "    predictions_test_y = multi_label_model_pipeline.predict(test_x)\n",
    "    return metrics.hamming_loss(y_true=test_y, y_pred=predictions_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 2257699.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1127703.17it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 2258509.99it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1502736.31it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1503813.88it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 2257429.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 2257429.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 2258239.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 902518.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1127299.05it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1505853.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 2257699.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1504653.06it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 2256619.80it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1128242.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1125618.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 2257429.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 2254463.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1503454.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1127905.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss for test data : 0.16986666666666667\n"
     ]
    }
   ],
   "source": [
    "multi_label_rf_br_model.fit(train_x, train_y)\n",
    "print('Hamming loss for test data :', hamming_loss(multi_label_rf_br_model,train_x,train_y,test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 2430697.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 902691.09it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1127568.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 2257159.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1811881.35it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1501182.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1504053.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1128242.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1503694.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 643846.77it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1503574.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 2250163.09it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1128107.58it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1127905.34it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 2255271.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 2223391.21it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1504173.41it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1830863.13it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 2257699.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4500/4500 [00:00<00:00, 1502855.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss for test data : 0.16866666666666666\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "\n",
    "classifier_chain_model = ClassifierChain(RandomForestClassifier(n_jobs=-1))\n",
    "multi_label_rf_cc_model = Pipeline(steps=[\n",
    "                           ('feature_union', fu),\n",
    "                           ('classifier_chain', classifier_chain_model)\n",
    "                        ])\n",
    "multi_label_rf_cc_model.fit(train_x, train_y)\n",
    "print('Hamming loss for test data :', hamming_loss(multi_label_rf_cc_model,train_x,train_y,test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def plot_roc_curve(x=None, y=None, classes=[],title=None):\n",
    "    \n",
    "    lw=2\n",
    "    plt.figure(figsize=(12,6))\n",
    "    for _class in classes:\n",
    "        \n",
    "         class_index = np.where(mlb.classes_ == _class)[0][0]\n",
    "         probs = binary_rel_model.classifiers_[class_index].predict_proba(fu.transform(x))[:,1]   \n",
    "         model_fpr, model_tpr, _ = roc_curve(y[:,class_index], probs)\n",
    "         roc_auc = auc(model_fpr, model_tpr)\n",
    "         plt.plot(model_fpr, model_tpr,\n",
    "             lw=lw, label='ROC curve -' + _class + '- (area = %0.2f)' % roc_auc)\n",
    "\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_roc_curve(x=test_x, y=test_y, classes=['normal-distribution','data-visualization','estimation'], \n",
    "               #title='ROC curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
